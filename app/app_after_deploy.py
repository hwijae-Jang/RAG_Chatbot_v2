"""
After ë²„ì „ í•­ê³µê¶Œ í™˜ë¶ˆ ìƒë‹´ RAG ì±—ë´‡ - Streamlit Cloud ë°°í¬ ì „ìš©

âš ï¸ ì¤‘ìš”: ì´ íŒŒì¼ì€ Streamlit Cloud ë°°í¬ ì „ìš©ì…ë‹ˆë‹¤!
ê°œë°œ/í…ŒìŠ¤íŠ¸ëŠ” app_after.pyë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

ì°¨ì´ì :
- Colab ë§¤ì§ ì»¤ë§¨ë“œ ì œê±° (%%writefile)
- ìƒëŒ€ ê²½ë¡œ ì‚¬ìš© (data/after/*.md)
- glob íŒ¨í„´ìœ¼ë¡œ íŒŒì¼ ê²€ìƒ‰
- ì—ëŸ¬ ë©”ì‹œì§€ ê°•í™”

ê°œë°œ í™˜ê²½: app_after.py (Colab í˜¸í™˜)
ë°°í¬ í™˜ê²½: app_after_deploy.py (Streamlit Cloud)

---
ê¸°ìˆ  ìŠ¤í™:
- chunk_size: 2000
- chunk_overlap: 400
- ë™ì˜ì–´ ì‚¬ì „: 50+
- ëŒ€í•œí•­ê³µ í†µí•© (6ê°œ md íŒŒì¼)
"""

import os
import glob
import streamlit as st
from pathlib import Path

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="After - í•­ê³µê¶Œ í™˜ë¶ˆ ì±—ë´‡",
    page_icon="âœˆï¸",
    layout="wide"
)

st.title("âœˆï¸ After ë²„ì „ - í™˜ë¶ˆ ìƒë‹´ ì±—ë´‡")
st.markdown("### ğŸŸ¢ ìµœì¢… ê°œì„  ë²„ì „ (ë°°í¬)")
st.caption("chunk_size=2000, overlap=400, ë™ì˜ì–´ 50+")

# ë™ì˜ì–´ ì‚¬ì „ (After í•µì‹¬ ê°œì„ )
SYNONYM_DICT = {
    # ë…¸ì‡¼ ê´€ë ¨
    "ë…¸ì‡¼": ["ë…¸ì‡¼", "No-Show", "no-show", "ë…¸ ì‡¼", "ë¯¸íƒ‘ìŠ¹", "ì˜ˆì•½ë¶€ë„"],
    "no-show": ["ë…¸ì‡¼", "No-Show", "no-show", "ë¯¸íƒ‘ìŠ¹", "ì˜ˆì•½ë¶€ë„"],
    "ì˜ˆì•½ë¶€ë„": ["ë…¸ì‡¼", "ì˜ˆì•½ë¶€ë„", "no-show", "ë¯¸íƒ‘ìŠ¹"],

    # í™˜ë¶ˆ ê´€ë ¨
    "í™˜ë¶ˆ": ["í™˜ë¶ˆ", "refund", "ë°˜í™˜", "ì·¨ì†Œí™˜ë¶ˆ"],
    "refund": ["í™˜ë¶ˆ", "refund", "ë°˜í™˜"],

    # ë³€ê²½ ê´€ë ¨
    "ë³€ê²½": ["ë³€ê²½", "change", "ìˆ˜ì •", "êµí™˜"],
    "change": ["ë³€ê²½", "change", "ìˆ˜ì •"],

    # ìˆ˜ìˆ˜ë£Œ ê´€ë ¨
    "ìˆ˜ìˆ˜ë£Œ": ["ìˆ˜ìˆ˜ë£Œ", "fee", "ìš”ê¸ˆ", "ë¹„ìš©", "charge", "ìœ„ì•½ê¸ˆ", "íŒ¨ë„í‹°", "penalty"],
    "fee": ["ìˆ˜ìˆ˜ë£Œ", "fee", "ìš”ê¸ˆ", "ë¹„ìš©", "charge", "ìœ„ì•½ê¸ˆ", "íŒ¨ë„í‹°", "penalty"],
    "ìœ„ì•½ê¸ˆ": ["ìœ„ì•½ê¸ˆ", "íŒ¨ë„í‹°", "penalty", "ìˆ˜ìˆ˜ë£Œ", "fee"],
    "penalty": ["ìœ„ì•½ê¸ˆ", "íŒ¨ë„í‹°", "penalty", "ìˆ˜ìˆ˜ë£Œ"],

    # ì·¨ì†Œ ê´€ë ¨
    "ì·¨ì†Œ": ["ì·¨ì†Œ", "cancel", "cancellation", "í•´ì§€"],
    "cancel": ["ì·¨ì†Œ", "cancel", "cancellation"],

    # ìš´ì„ ì¢…ë¥˜
    "íŠ¹ê°€": ["íŠ¹ê°€", "íŠ¹ê°€ìš´ì„", "í”„ë¡œëª¨ì…˜", "promotion", "special"],
    "í• ì¸": ["í• ì¸", "í• ì¸ìš´ì„", "discount", "ì„¸ì¼", "sale"],
    "ì¼ë°˜": ["ì¼ë°˜", "ì¼ë°˜ìš´ì„", "ì •ìƒ", "ì •ìƒìš´ì„", "normal", "regular"],

    # ìš´ì„ ë“±ê¸‰
    "ë² ì´ì§": ["ë² ì´ì§", "BASIC", "Basic", "basic"],
    "basic": ["ë² ì´ì§", "BASIC", "Basic"],
    "ìŠ¤íƒ ë‹¤ë“œ": ["ìŠ¤íƒ ë‹¤ë“œ", "STANDARD", "Standard", "standard"],
    "standard": ["ìŠ¤íƒ ë‹¤ë“œ", "STANDARD", "Standard"],
    "í”Œë ‰ìŠ¤": ["í”Œë ‰ìŠ¤", "FLEX", "Flex", "flex", "flexible"],
    "flex": ["í”Œë ‰ìŠ¤", "FLEX", "Flex", "flexible"],
    "ì„¸ì´ë²„": ["ì„¸ì´ë²„", "SAVER", "Saver", "saver"],
    "saver": ["ì„¸ì´ë²„", "SAVER", "Saver"],

    # ë…¸ì„  ê´€ë ¨
    "êµ­ë‚´ì„ ": ["êµ­ë‚´ì„ ", "domestic", "êµ­ë‚´"],
    "domestic": ["êµ­ë‚´ì„ ", "domestic"],
    "êµ­ì œì„ ": ["êµ­ì œì„ ", "international", "êµ­ì œ", "í•´ì™¸"],
    "international": ["êµ­ì œì„ ", "international"],

    # íƒ‘ìŠ¹ìˆ˜ì† ê´€ë ¨
    "íƒ‘ìŠ¹ìˆ˜ì†": ["íƒ‘ìŠ¹ìˆ˜ì†", "ì²´í¬ì¸", "check-in", "ìˆ˜ì†"],
    "ì²´í¬ì¸": ["íƒ‘ìŠ¹ìˆ˜ì†", "ì²´í¬ì¸", "check-in"],
    "check-in": ["íƒ‘ìŠ¹ìˆ˜ì†", "ì²´í¬ì¸", "check-in"],

    # ê²Œì´íŠ¸ ê´€ë ¨
    "ê²Œì´íŠ¸": ["ê²Œì´íŠ¸", "gate", "ì¶œêµ¬ì¥"],
    "gate": ["ê²Œì´íŠ¸", "gate"],

    # ë¯¸íƒ‘ìŠ¹
    "ë¯¸íƒ‘ìŠ¹": ["ë¯¸íƒ‘ìŠ¹", "no-show", "ë¯¸ìŠ¹ì„ ", "ë¶ˆíƒ‘ìŠ¹"]
}

def expand_query_with_synonyms(query: str) -> str:
    """ë™ì˜ì–´ë¥¼ í™œìš©í•œ ì¿¼ë¦¬ í™•ì¥"""
    words = query.split()
    expanded_terms = []

    for word in words:
        word_lower = word.lower()
        if word_lower in SYNONYM_DICT:
            synonyms = SYNONYM_DICT[word_lower]
            expanded_terms.extend(synonyms[:3])
        expanded_terms.append(word)

    return " ".join(expanded_terms)

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("ğŸ“š After ì„¤ì •")
    st.success("âœ… ìµœì¢… ê°œì„  ë²„ì „")
    st.info("ğŸš€ Streamlit Cloud ë°°í¬ ë²„ì „")

    # API í‚¤ ì…ë ¥
    api_key = st.text_input(
        "OpenAI API Key",
        type="password",
        value=os.getenv("OPENAI_API_KEY", ""),
        help="Streamlit Cloud Secretsì— ì„¤ì •í•˜ê±°ë‚˜ ì—¬ê¸°ì— ì…ë ¥í•˜ì„¸ìš”"
    )
    if api_key:
        os.environ["OPENAI_API_KEY"] = api_key

    k = st.slider("ê²€ìƒ‰ ê°œìˆ˜ k", 1, 5, 3)
    show_sources = st.checkbox("ê·¼ê±° í‘œì‹œ", value=True)
    use_synonyms = st.checkbox("ë™ì˜ì–´ í™•ì¥", value=True)

    st.divider()

    st.header("â“ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸")
    test_questions = [
        "ì œì£¼í•­ê³µ ë…¸ì‡¼ ìœ„ì•½ê¸ˆì€?",
        "ì§„ì—ì–´ êµ­ë‚´ì„  ë…¸ì‡¼ ìœ„ì•½ê¸ˆì€ ì–¼ë§ˆì¸ê°€ìš”?",
        "no-show penalty",
        "ëŒ€í•œí•­ê³µ êµ­ì œì„  í™˜ë¶ˆ ìˆ˜ìˆ˜ë£Œ í‘œ",
        "ì œì£¼í•­ê³µ FLEX ìš´ì„ í™˜ë¶ˆ"
    ]

    for q in test_questions:
        if st.button(q, key=q):
            st.session_state["question"] = q

    st.divider()
    if st.button("ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.pop("messages", None)
        st.rerun()

    # ë™ì˜ì–´ ì •ë³´ í‘œì‹œ
    st.divider()
    with st.expander("ğŸ” ë™ì˜ì–´ ì‚¬ì „ ì •ë³´"):
        st.caption(f"ì´ {len(SYNONYM_DICT)}ê°œ í‚¤ì›Œë“œ")
        st.caption("ì˜ˆ: ë…¸ì‡¼ â†’ no-show, ì˜ˆì•½ë¶€ë„")

    st.divider()
    with st.expander("â„¹ï¸ ë²„ì „ ì •ë³´"):
        st.caption("**ë°°í¬ ë²„ì „**: app_after_deploy.py")
        st.caption("**ê°œë°œ ë²„ì „**: app_after.py (Colab)")
        st.caption("**Chunk Size**: 2000")
        st.caption("**ë™ì˜ì–´**: 50+")

# ì„¸ì…˜ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state["messages"] = []
if "question" not in st.session_state:
    st.session_state["question"] = None

# API í‚¤ í™•ì¸
if not os.getenv("OPENAI_API_KEY"):
    st.warning("âš ï¸ OpenAI API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”")
    st.info("""
    **Streamlit Cloud ë°°í¬ ì‹œ:**
    1. Settings â†’ Secrets ë©”ë‰´
    2. ë‹¤ìŒ ë‚´ìš© ì…ë ¥:
    ```
    OPENAI_API_KEY = "sk-..."
    ```
    
    **ë¡œì»¬ í…ŒìŠ¤íŠ¸ ì‹œ:**
    ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ ì…ë ¥
    """)
    st.stop()

# LLM ì´ˆê¸°í™”
@st.cache_resource
def init_llm():
    return ChatOpenAI(
        model='gpt-4o-mini',
        temperature=0,
        api_key=os.environ.get("OPENAI_API_KEY")
    )

llm = init_llm()

# í”„ë¡¬í”„íŠ¸
rag_prompt = ChatPromptTemplate.from_template("""
ë„ˆëŠ” í•­ê³µê¶Œ í™˜ë¶ˆ ë° ë³€ê²½ì„ ë„ì™€ì£¼ëŠ” ì¹œì ˆí•œ í•œêµ­ì–´ ìƒë‹´ ì±—ë´‡ì´ì•¼.
ì•„ë˜ í•­ê³µì‚¬ ì •ì±… ë¬¸ì„œë¥¼ ì°¸ê³ í•´ì„œ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì¤˜.

ì •ì±…ë¬¸ì„œ: {context}
ì‚¬ìš©ì ì§ˆë¬¸: {q}

ë‹µë³€ ì‘ì„± ì‹œ ìœ ì˜ì‚¬í•­:
1. ë¬¸ì„œì— ìˆëŠ” ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ë˜, ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì¤˜
2. í™˜ë¶ˆ/ë³€ê²½ ìˆ˜ìˆ˜ë£Œ, ê¸°ê°„ ë“± êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ëª…í™•íˆ ì œì‹œí•´ì¤˜
3. í‘œ(í…Œì´ë¸”) í˜•ì‹ì˜ ì •ë³´ê°€ ìˆë‹¤ë©´ **ì „ì²´ ë‚´ìš©**ì„ ë¹ ì§ì—†ì´ í¬í•¨í•´ì¤˜
4. ìš´ì„ ë“±ê¸‰ë³„ ì°¨ì´ê°€ ìˆë‹¤ë©´ ëª…í™•íˆ êµ¬ë¶„í•´ì„œ ì„¤ëª…í•´ì¤˜
5. ë‹µë³€ ë§ˆì§€ë§‰ì— "âš ï¸ ì •í™•í•œ ì •ë³´ëŠ” í•­ê³µì‚¬ ê³µì‹ ì›¹ì‚¬ì´íŠ¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”"ë¼ê³  ì•ˆë‚´í•´ì¤˜

ë‹µë³€:
""")

rag_chain = rag_prompt | llm | StrOutputParser()

# ë²¡í„° DB ì´ˆê¸°í™”
@st.cache_resource
def initialize_vectordb():
    """
    After ì„¤ì •ìœ¼ë¡œ ë²¡í„° DB ì´ˆê¸°í™”
    Streamlit Cloud ë°°í¬ ìµœì í™” ë²„ì „
    """

    # MD íŒŒì¼ ê²½ë¡œ íŒ¨í„´ (ìš°ì„ ìˆœìœ„ ìˆœ)
    patterns = [
        "data/after/*.md",       # Streamlit Cloud (ìƒëŒ€ ê²½ë¡œ)
        "./data/after/*.md",     # ë¡œì»¬ ì‹¤í–‰
        "../data/after/*.md",    # app/ í´ë”ì—ì„œ ì‹¤í–‰ ì‹œ
    ]

    # íŒŒì¼ ê²€ìƒ‰
    seen = set()
    loader_files = []

    for pat in patterns:
        for fp in glob.glob(pat, recursive=True):
            if fp.endswith(".md") and fp not in seen and Path(fp).is_file():
                seen.add(fp)
                loader_files.append(fp)

    # ë¡œë“œ ê²°ê³¼ í‘œì‹œ
    st.sidebar.caption(f"ğŸ“„ ë¡œë“œëœ MD íŒŒì¼: {len(loader_files)}ê°œ")
    
    if loader_files:
        with st.sidebar.expander("ğŸ“‚ ë¡œë“œëœ íŒŒì¼ ëª©ë¡", expanded=False):
            for fp in sorted(loader_files):
                filename = Path(fp).name
                # í•­ê³µì‚¬ëª… ì¶”ì¶œ
                airline = filename.split('_')[0] if '_' in filename else filename
                st.text(f"âœ… {airline}")

    if not loader_files:
        st.error("âŒ MD íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        st.info("""
        ## ğŸ“‚ í”„ë¡œì íŠ¸ êµ¬ì¡° í™•ì¸
        
        **í•„ìš”í•œ êµ¬ì¡°:**
        ```
        RAG_Chatbot_v2/
        â”œâ”€â”€ app/
        â”‚   â””â”€â”€ app_after_deploy.py  â† ì´ íŒŒì¼
        â””â”€â”€ data/
            â””â”€â”€ after/               â† MD íŒŒì¼ ìœ„ì¹˜
                â”œâ”€â”€ ì œì£¼í•­ê³µ_í™˜ë¶ˆê·œì •.md
                â”œâ”€â”€ ì§„ì—ì–´_í™˜ë¶ˆê·œì •.md
                â”œâ”€â”€ ëŒ€í•œí•­ê³µ_í™˜ë¶ˆê·œì •.md
                â”œâ”€â”€ ì•„ì‹œì•„ë‚˜_í™˜ë¶ˆê·œì •.md
                â”œâ”€â”€ ì´ìŠ¤íƒ€í•­ê³µ_í™˜ë¶ˆê·œì •.md
                â””â”€â”€ ì—ì–´ì„œìš¸_í™˜ë¶ˆê·œì •.md
        ```
        
        **í•´ê²° ë°©ë²•:**
        1. GitHub ë¦¬í¬ì§€í† ë¦¬ì— `data/after/*.md` íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
        2. Streamlit Cloud ì„¤ì •ì—ì„œ **Main file path**ê°€ `app/app_after_deploy.py`ì¸ì§€ í™•ì¸
        3. ë¦¬í¬ì§€í† ë¦¬ë¥¼ ë‹¤ì‹œ cloneí•˜ê±°ë‚˜ íŒŒì¼ ê²½ë¡œ í™•ì¸
        """)
        st.stop()

    # MD íŒŒì¼ ë¡œë“œ
    docs = []
    load_errors = []
    
    for md_file in loader_files:
        try:
            loader = TextLoader(str(md_file), encoding='utf-8')
            file_docs = loader.load()

            for doc in file_docs:
                doc.metadata['source'] = Path(md_file).name
                doc.metadata['filepath'] = str(md_file)

            docs.extend(file_docs)
        except Exception as e:
            load_errors.append(f"{Path(md_file).name}: {str(e)}")

    if load_errors:
        with st.sidebar.expander("âš ï¸ ë¡œë“œ ì‹¤íŒ¨ íŒŒì¼", expanded=False):
            for err in load_errors:
                st.caption(err)

    if not docs:
        st.error("âŒ MD íŒŒì¼ì„ ë¡œë“œí–ˆì§€ë§Œ ë‚´ìš©ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤")
        st.stop()

    # After ì„¤ì •ìœ¼ë¡œ ì²­í‚¹
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=2000,
        chunk_overlap=400
    )
    chunks = splitter.split_documents(docs)

    # ë²¡í„° DB ìƒì„±
    embeddings = OpenAIEmbeddings(
        model='text-embedding-3-small',
        api_key=os.environ.get("OPENAI_API_KEY")
    )

    db = Chroma.from_documents(
        documents=chunks,
        embedding=embeddings,
        collection_name="after_chatbot_deploy"
    )

    return db, len(docs), len(chunks)

# ë²¡í„° DB ì´ˆê¸°í™”
with st.spinner("ğŸ”„ ë²¡í„° DB ì´ˆê¸°í™” ì¤‘..."):
    try:
        db, num_docs, num_chunks = initialize_vectordb()
        st.sidebar.success(f"âœ… {num_docs}ê°œ ë¬¸ì„œ, {num_chunks}ê°œ ì²­í¬")
    except Exception as e:
        st.error(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        st.stop()

# ë¼ìš°íŒ… í‚¤ì›Œë“œ
RAG_KEYWORDS = [
    "í™˜ë¶ˆ", "ë¶ˆí™˜", "ë°˜í™˜", "ëŒë ¤", "ëŒë ¤ë°›", "ë¦¬í€", "refund",
    "ì·¨ì†Œ", "ìº”ìŠ¬", "cancel", "cancellation", "í•´ì§€", "ì² íšŒ",
    "ë³€ê²½", "ìˆ˜ì •", "êµí™˜", "ë°”ê¾¸", "ë°”ê¿”", "change", "modify",
    "ìˆ˜ìˆ˜ë£Œ", "fee", "charge", "ë¹„ìš©", "ìš”ê¸ˆ", "ê¸ˆì•¡",
    "ìœ„ì•½ê¸ˆ", "íŒ¨ë„í‹°", "penalty", "ë²Œê¸ˆ",
    "í•­ê³µê¶Œ", "í‹°ì¼“", "ticket", "í‘œ", "ë¹„í–‰ê¸°í‘œ",
    "ìš´ì„", "fare", "ë“±ê¸‰", "í´ë˜ìŠ¤",
    "flex", "flexible", "í”Œë ‰ìŠ¤", "standard", "ìŠ¤íƒ ë‹¤ë“œ",
    "saver", "ì„¸ì´ë²„", "basic", "ë² ì´ì§",
    "íŠ¹ê°€", "í• ì¸", "ì¼ë°˜", "í”„ë¡œëª¨ì…˜",
    "êµ­ë‚´ì„ ", "êµ­ë‚´", "domestic", "êµ­ì œì„ ", "êµ­ì œ", "international",
    "ë…¸ì‡¼", "no-show", "ë¯¸íƒ‘ìŠ¹", "ì˜ˆì•½ë¶€ë„",
    "ê²Œì´íŠ¸", "gate", "íƒ‘ìŠ¹ìˆ˜ì†", "ì²´í¬ì¸", "check-in",
    "ëŒ€í•œí•­ê³µ", "ì•„ì‹œì•„ë‚˜", "ì œì£¼í•­ê³µ", "ì§„ì—ì–´", "í‹°ì›¨ì´", "ì—ì–´ì„œìš¸", "ì´ìŠ¤íƒ€í•­ê³µ",
]

def route_to_rag(q):
    """ë¼ìš°íŒ… íŒë‹¨"""
    ql = q.lower()
    return any(kw.lower() in ql for kw in RAG_KEYWORDS)

def refund_rag(question, k_val, use_syn):
    """RAG ê²€ìƒ‰ ë° ë‹µë³€"""
    search_query = expand_query_with_synonyms(question) if use_syn else question
    results = db.similarity_search_with_relevance_scores(search_query, k=k_val)

    if not results:
        return "âŒ ê´€ë ¨ ê·œì •ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.", []

    context = "\n\n".join([doc.page_content for doc, score in results])
    answer = rag_chain.invoke({'context': context, 'q': question})

    sources = []
    for doc, score in results:
        sources.append({
            'filename': doc.metadata.get('source', 'unknown'),
            'score': score,
            'content': doc.page_content[:150]
        })

    return answer, sources

# ì±„íŒ… UI
for msg in st.session_state["messages"]:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# ì…ë ¥ ì²˜ë¦¬
if st.session_state["question"]:
    question = st.session_state["question"]
    st.session_state["question"] = None
else:
    question = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")

if question:
    with st.chat_message("user"):
        st.markdown(question)
    st.session_state["messages"].append({"role": "user", "content": question})

    with st.chat_message("assistant"):
        if route_to_rag(question):
            with st.spinner("ğŸ” ê²€ìƒ‰ ì¤‘..."):
                answer, sources = refund_rag(question, k, use_synonyms)

            st.markdown(answer)

            if sources:
                st.success(f"âœ… {len(sources)}ê°œ ë¬¸ì„œ ê²€ìƒ‰ ì™„ë£Œ")
            else:
                st.error("âŒ ê²€ìƒ‰ ì‹¤íŒ¨")

            if show_sources and sources:
                with st.expander("ğŸ” ì°¸ê³  ë¬¸ì„œ"):
                    for i, src in enumerate(sources, 1):
                        st.markdown(f"**{i}. {src['filename']}** (ìœ ì‚¬ë„: {src['score']:.2f})")
                        st.caption(src['content'][:100] + "...")
                        st.divider()
        else:
            answer = "ì£„ì†¡í•©ë‹ˆë‹¤. í•­ê³µê¶Œ í™˜ë¶ˆ/ë³€ê²½ ê´€ë ¨ ì§ˆë¬¸ì´ ì•„ë‹Œ ê²ƒ ê°™ìŠµë‹ˆë‹¤."
            st.markdown(answer)

    st.session_state["messages"].append({"role": "assistant", "content": answer})

# í•˜ë‹¨ ì •ë³´
st.markdown("---")
st.caption("ğŸŸ¢ After ë²„ì „ - ìµœì¢… ê°œì„  (Streamlit Cloud ë°°í¬)")
st.caption("íŠ¹ì§•: chunk_size=2000, ë™ì˜ì–´ 50+, í”„ë¡¬í”„íŠ¸ ê°œì„ , ëŒ€í•œí•­ê³µ í†µí•©")
