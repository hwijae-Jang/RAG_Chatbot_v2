
'''
3ë‹¨ê³„ LLM í‰ê°€ ê°€ì¤‘ì¹˜ ì¡°ì ˆ ì‹œê°í™”

'''
import json
import matplotlib.pyplot as plt
import numpy as np
from pathlib import Path

# í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False


def load_results(filename: str) -> dict:
    """í‰ê°€ ê²°ê³¼ ë¡œë“œ"""
    with open(filename, 'r', encoding='utf-8') as f:
        return json.load(f)


def plot_3stage_keyword_accuracy(before_m, middle_m, after_m):
    """3ë‹¨ê³„ í‚¤ì›Œë“œ ì •í™•ë„ ë¹„êµ"""
    fig, ax = plt.subplots(figsize=(12, 7))

    versions = ['Before', 'Middle', 'After']
    scores = [
        before_m['avg_keyword_score'] * 100,
        middle_m['avg_keyword_score'] * 100,
        after_m['avg_keyword_score'] * 100
    ]

    colors = ['#ff6b6b', '#ffd93d', '#51cf66']
    bars = ax.bar(versions, scores, color=colors, alpha=0.8, edgecolor='black', linewidth=2, width=0.6)

    # ê°’ í‘œì‹œ
    for bar, score in zip(bars, scores):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height + 1,
                f'{score:.1f}%',
                ha='center', va='bottom', fontsize=16, fontweight='bold')

    # ê°œì„ ìœ¨ í™”ì‚´í‘œ (Before â†’ Middle)
    improvement1 = scores[1] - scores[0]
    ax.annotate(f'+{improvement1:.1f}%p\n(Document\nOptimization)',
                xy=(1, scores[1]), xytext=(0.5, (scores[0] + scores[1])/2 + 3),
                arrowprops=dict(arrowstyle='->', lw=2, color='orange'),
                fontsize=11, color='orange', fontweight='bold', ha='center')

    # ê°œì„ ìœ¨ í™”ì‚´í‘œ (Middle â†’ After)
    improvement2 = scores[2] - scores[1]
    ax.annotate(f'+{improvement2:.1f}%p\n(Code\nOptimization)',
                xy=(2, scores[2]), xytext=(1.5, (scores[1] + scores[2])/2 + 3),
                arrowprops=dict(arrowstyle='->', lw=2, color='green'),
                fontsize=11, color='green', fontweight='bold', ha='center')

    ax.set_ylabel('Keyword Accuracy (%)', fontsize=13)
    ax.set_title('3-Stage Improvement: Keyword Accuracy', fontsize=15, fontweight='bold')
    ax.set_ylim(0, 100)
    ax.grid(axis='y', alpha=0.3)

    # ëª©í‘œì„ 
    ax.axhline(y=70, color='blue', linestyle='--', alpha=0.5, linewidth=1.5, label='Target: 70%')
    ax.legend(fontsize=11)

    plt.tight_layout()
    plt.savefig('3stage_keyword_accuracy.png', dpi=300, bbox_inches='tight')
    print("ğŸ“Š ì €ì¥: 3stage_keyword_accuracy.png")


def plot_3stage_search_success(before_m, middle_m, after_m):
    """3ë‹¨ê³„ ê²€ìƒ‰ ì„±ê³µë¥  ë¹„êµ"""
    fig, ax = plt.subplots(figsize=(12, 7))

    versions = ['Before', 'Middle', 'After']
    rates = [
        before_m['search_success_rate'] * 100,
        middle_m['search_success_rate'] * 100,
        after_m['search_success_rate'] * 100
    ]

    colors = ['#ff6b6b', '#ffd93d', '#51cf66']
    bars = ax.bar(versions, rates, color=colors, alpha=0.8, edgecolor='black', linewidth=2, width=0.6)

    # ê°’ í‘œì‹œ
    for bar, rate in zip(bars, rates):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height + 1,
                f'{rate:.1f}%',
                ha='center', va='bottom', fontsize=16, fontweight='bold')

    # ê°œì„ ìœ¨ í‘œì‹œ
    improvement1 = rates[1] - rates[0]
    if improvement1 > 0:
        ax.annotate(f'+{improvement1:.1f}%p',
                    xy=(1, rates[1]), xytext=(0.5, (rates[0] + rates[1])/2 + 2),
                    arrowprops=dict(arrowstyle='->', lw=2, color='orange'),
                    fontsize=11, color='orange', fontweight='bold')

    improvement2 = rates[2] - rates[1]
    if improvement2 > 0:
        ax.annotate(f'+{improvement2:.1f}%p',
                    xy=(2, rates[2]), xytext=(1.5, (rates[1] + rates[2])/2 + 2),
                    arrowprops=dict(arrowstyle='->', lw=2, color='green'),
                    fontsize=11, color='green', fontweight='bold')

    ax.set_ylabel('Search Success Rate (%)', fontsize=13)
    ax.set_title('3-Stage Improvement: Search Success Rate', fontsize=15, fontweight='bold')
    ax.set_ylim(0, 110)
    ax.grid(axis='y', alpha=0.3)

    # ëª©í‘œì„ 
    ax.axhline(y=100, color='blue', linestyle='--', alpha=0.5, linewidth=1.5, label='Target: 100%')
    ax.legend(fontsize=11)

    plt.tight_layout()
    plt.savefig('3stage_search_success.png', dpi=300, bbox_inches='tight')
    print("ğŸ“Š ì €ì¥: 3stage_search_success.png")


def plot_improvement_breakdown(before_m, middle_m, after_m):
    """ê°œì„  ê¸°ì—¬ë„ ë¶„í•´ ë¶„ì„"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))

    # í‚¤ì›Œë“œ ì •í™•ë„ ê°œì„  ë¶„í•´
    before_kw = before_m['avg_keyword_score'] * 100
    middle_kw = middle_m['avg_keyword_score'] * 100
    after_kw = after_m['avg_keyword_score'] * 100

    doc_improvement = middle_kw - before_kw
    code_improvement = after_kw - middle_kw
    total_improvement = after_kw - before_kw

    # For the pie chart, we only consider positive contributions.
    # If a stage resulted in a decrease, its 'contribution to improvement' for the pie chart is 0.
    positive_doc_improvement_for_pie = max(0, doc_improvement)
    positive_code_improvement_for_pie = max(0, code_improvement)

    # Sum of only the positive improvements for the pie chart's denominator
    sum_of_positive_improvements = positive_doc_improvement_for_pie + positive_code_improvement_for_pie

    pie_labels = []
    pie_sizes_for_chart = []
    pie_colors_for_chart = []
    colors_map = {'Document': '#ffd93d', 'Code': '#51cf66'}

    if sum_of_positive_improvements > 0:
        if positive_doc_improvement_for_pie > 0:
            pie_labels.append(f'Document\nOptimization\n({doc_improvement:.1f}%p)')
            pie_sizes_for_chart.append(positive_doc_improvement_for_pie)
            pie_colors_for_chart.append(colors_map['Document'])

        if positive_code_improvement_for_pie > 0:
            pie_labels.append(f'Code\nOptimization\n({code_improvement:.1f}%p)')
            pie_sizes_for_chart.append(positive_code_improvement_for_pie)
            pie_colors_for_chart.append(colors_map['Code'])

    # íŒŒì´ ì°¨íŠ¸
    if not pie_sizes_for_chart:
        ax1.text(0, 0, 'No Positive\nContribution to Improvement', horizontalalignment='center', verticalalignment='center',
                 fontsize=12, color='gray', fontweight='bold')
    else:
        wedges, texts = ax1.pie(pie_sizes_for_chart, labels=pie_labels, colors=pie_colors_for_chart, startangle=90,
                                 textprops={'fontsize': 11, 'fontweight': 'bold'}, wedgeprops=dict(width=0.3))

    ax1.set_title('Improvement Contribution\n(Keyword Accuracy)', fontsize=13, fontweight='bold')

    # ëˆ„ì  ê°œì„  ê·¸ë˜í”„
    stages = ['Before', 'Middle', 'After']

    ax2.plot(stages, [before_kw, middle_kw, after_kw], marker='o', markersize=12,
             linewidth=3, color='#4dabf7', label='Actual Score')
    ax2.fill_between(range(3), before_kw, [before_kw, middle_kw, after_kw],
                     alpha=0.3, color='#4dabf7')

    # ê°œì„ ëŸ‰ í‘œì‹œ
    ax2.annotate(f'+{doc_improvement:.1f}%p\nDoc Opt',
                xy=(1, middle_kw), xytext=(0.7, middle_kw + 5),
                arrowprops=dict(arrowstyle='->', color='orange', lw=1.5),
                fontsize=10, color='orange', fontweight='bold')

    ax2.annotate(f'{code_improvement:+.1f}%p\nCode Opt',
                xy=(2, after_kw), xytext=(1.7, after_kw + 5),
                arrowprops=dict(arrowstyle='->', color='green', lw=1.5),
                fontsize=10, color='green', fontweight='bold')

    ax2.set_ylabel('Keyword Accuracy (%)', fontsize=12)
    ax2.set_title('Cumulative Improvement', fontsize=13, fontweight='bold')
    ax2.grid(alpha=0.3)
    ax2.legend(fontsize=11)
    ax2.set_ylim(0, 100)

    plt.tight_layout()
    plt.savefig('improvement_breakdown.png', dpi=300, bbox_inches='tight')
    print("ğŸ“Š ì €ì¥: improvement_breakdown.png")


def plot_response_time_comparison(before_m, middle_m, after_m):
    """3ë‹¨ê³„ ì‘ë‹µ ì‹œê°„ ë¹„êµ"""
    fig, ax = plt.subplots(figsize=(12, 7))

    versions = ['Before', 'Middle', 'After']
    times = [
        before_m['avg_response_time'],
        middle_m['avg_response_time'],
        after_m['avg_response_time']
    ]

    colors = ['#ff6b6b', '#ffd93d', '#51cf66']
    bars = ax.bar(versions, times, color=colors, alpha=0.8, edgecolor='black', linewidth=2, width=0.6)

    # ê°’ í‘œì‹œ
    for bar, time_val in zip(bars, times):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height + 0.05,
                f'{time_val:.2f}s',
                ha='center', va='bottom', fontsize=16, fontweight='bold')

    ax.set_ylabel('Average Response Time (seconds)', fontsize=13)
    ax.set_title('3-Stage Comparison: Response Time', fontsize=15, fontweight='bold')
    ax.grid(axis='y', alpha=0.3)

    # ëª©í‘œì„ 
    ax.axhline(y=3.0, color='red', linestyle='--', alpha=0.5, linewidth=1.5, label='Limit: 3.0s')
    ax.legend(fontsize=11)

    plt.tight_layout()
    plt.savefig('3stage_response_time.png', dpi=300, bbox_inches='tight')
    print("ğŸ“Š ì €ì¥: 3stage_response_time.png")


def generate_3stage_report(data):
    """3ë‹¨ê³„ í…ìŠ¤íŠ¸ ë¦¬í¬íŠ¸"""
    before_m = data['before']['metrics']
    middle_m = data['middle']['metrics']
    after_m = data['after']['metrics']

    # ê°œì„ ìœ¨ ê³„ì‚°
    kw_b_m = (middle_m['avg_keyword_score'] - before_m['avg_keyword_score']) * 100
    kw_m_a = (after_m['avg_keyword_score'] - middle_m['avg_keyword_score']) * 100
    kw_total = (after_m['avg_keyword_score'] - before_m['avg_keyword_score']) * 100

    sr_b_m = (middle_m['search_success_rate'] - before_m['search_success_rate']) * 100
    sr_m_a = (after_m['search_success_rate'] - middle_m['search_success_rate']) * 100
    sr_total = (after_m['search_success_rate'] - before_m['search_success_rate']) * 100

    # ê¸°ì—¬ìœ¨ ê³„ì‚°
    doc_contribution = (kw_b_m / kw_total * 100) if kw_total > 0 else 0
    code_contribution = (kw_m_a / kw_total * 100) if kw_total > 0 else 0

    report = f"""
{'='*70}
í•­ê³µê¶Œ í™˜ë¶ˆ ì±—ë´‡ - 3ë‹¨ê³„ ì„±ëŠ¥ í‰ê°€ ë¦¬í¬íŠ¸
{'='*70}

ğŸ“… í‰ê°€ ì¼ì‹œ: {data['timestamp']}
ğŸ“Š ì´ í‰ê°€ ì§ˆë¬¸: 15ê°œ

{'='*70}
ë‹¨ê³„ë³„ ì„±ëŠ¥ ë¹„êµ
{'='*70}

1. í‚¤ì›Œë“œ ì •í™•ë„
   Before: {before_m['avg_keyword_score']:.1%}
   Middle: {middle_m['avg_keyword_score']:.1%} (+{kw_b_m:.1f}%p)
   After:  {after_m['avg_keyword_score']:.1%} (+{kw_m_a:.1f}%p)
   ì´ ê°œì„ : +{kw_total:.1f}%p

2. ê²€ìƒ‰ ì„±ê³µë¥ 
   Before: {before_m['search_success_rate']:.1%}
   Middle: {middle_m['search_success_rate']:.1%} (+{sr_b_m:.1f}%p)
   After:  {after_m['search_success_rate']:.1%} (+{sr_m_a:.1f}%p)
   ì´ ê°œì„ : +{sr_total:.1f}%p

3. í‰ê·  ì‘ë‹µ ì‹œê°„
   Before: {before_m['avg_response_time']:.2f}ì´ˆ
   Middle: {middle_m['avg_response_time']:.2f}ì´ˆ
   After:  {after_m['avg_response_time']:.2f}ì´ˆ

{'='*70}
ê°œì„  ê¸°ì—¬ë„ ë¶„ì„
{'='*70}

ë¬¸ì„œ ìµœì í™” (Before â†’ Middle):
   â€¢ í‚¤ì›Œë“œ ì •í™•ë„: +{kw_b_m:.1f}%p
   â€¢ ì „ì²´ ê¸°ì—¬ìœ¨: {doc_contribution:.1f}%
   â€¢ ì£¼ìš” ë³€ê²½: ë™ì˜ì–´ 30ê°œ ì¶”ê°€, ë¬¸ì„œ êµ¬ì¡° ê°œì„ 

ì½”ë“œ ìµœì í™” (Middle â†’ After):
   â€¢ í‚¤ì›Œë“œ ì •í™•ë„: +{kw_m_a:.1f}%p
   â€¢ ì „ì²´ ê¸°ì—¬ìœ¨: {code_contribution:.1f}%
   â€¢ ì£¼ìš” ë³€ê²½: chunk 2000ìœ¼ë¡œ í™•ëŒ€, ë™ì˜ì–´ 50+ í™•ì¥

{'='*70}
í•µì‹¬ ê°œì„  ì‚¬í•­
{'='*70}

Stage 1 (Before â†’ Middle): ë¬¸ì„œ ìµœì í™”
   âœ… ë™ì˜ì–´ ì‚¬ì „ êµ¬ì¶• (0 â†’ 30ê°œ)
   âœ… MD íŒŒì¼ êµ¬ì¡° ê°œì„ 
   âœ… Chunk í¬ê¸° í™•ëŒ€ (800 â†’ 1200)

Stage 2 (Middle â†’ After): ì½”ë“œ ìµœì í™”
   âœ… ë™ì˜ì–´ ëŒ€í­ í™•ì¥ (30 â†’ 50+ê°œ)
   âœ… Chunk í¬ê¸° ìµœì í™” (1200 â†’ 2000)
   âœ… í”„ë¡¬í”„íŠ¸ ìƒì„¸í™” (í‘œ ì™„ì „ í¬í•¨ ëª…ì‹œ)
   âœ… ëŒ€í•œí•­ê³µ ë¬¸ì„œ í†µí•© (3ê°œ â†’ 1ê°œ)

{'='*70}
"""

    with open('evaluation_3stages_report.txt', 'w', encoding='utf-8') as f:
        f.write(report)

    print(report)
    print("ğŸ“„ ì €ì¥: evaluation_3stages_report.txt")


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    print("="*70)
    print("ğŸ“Š 3ë‹¨ê³„ í‰ê°€ ê²°ê³¼ ì‹œê°í™”")
    print("="*70)

    # ìµœê·¼ ê²°ê³¼ íŒŒì¼ ì°¾ê¸°
    result_files = list(Path('.').glob('evaluation_3stages_*.json'))

    if not result_files:
        print("âŒ 3ë‹¨ê³„ í‰ê°€ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ë¨¼ì € evaluate_3stages.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return

    latest_file = max(result_files, key=lambda p: p.stat().st_mtime)
    print(f"ğŸ“‚ ê²°ê³¼ íŒŒì¼: {latest_file}")

    # ë°ì´í„° ë¡œë“œ
    data = load_results(latest_file)
    before_m = data['before']['metrics']
    middle_m = data['middle']['metrics']
    after_m = data['after']['metrics']

    print("\nğŸ“Š ê·¸ë˜í”„ ìƒì„± ì¤‘...")

    # ê·¸ë˜í”„ ìƒì„±
    plot_3stage_keyword_accuracy(before_m, middle_m, after_m)
    plot_3stage_search_success(before_m, middle_m, after_m)
    plot_improvement_breakdown(before_m, middle_m, after_m)
    plot_response_time_comparison(before_m, middle_m, after_m)

    # í…ìŠ¤íŠ¸ ë¦¬í¬íŠ¸
    print("\nğŸ“„ í…ìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
    generate_3stage_report(data)

    print("\nâœ… ëª¨ë“  ì‹œê°í™” ì™„ë£Œ!")
    print("\nìƒì„±ëœ íŒŒì¼:")
    print("   â€¢ 3stage_keyword_accuracy.png")
    print("   â€¢ 3stage_search_success.png")
    print("   â€¢ improvement_breakdown.png")
    print("   â€¢ 3stage_response_time.png")
    print("   â€¢ evaluation_3stages_report.txt")


if __name__ == "__main__":
    main()